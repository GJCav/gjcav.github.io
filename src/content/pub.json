[
    {
        "bibtex": "@inproceedings{ccks2023,\n    title={面向含表格文档的中文篇章级事件抽取模型},\n    author={吴孟松 and 朱桐 and 张国梁 and 任俊飞 and 余子健 and 陈文亮},\n    booktitle={China Conference on Knowledge Graph and Semantic Computing (CCKS)},\n    year={2023},\n    abstract={篇章级事件抽取任务，即从长文档中提取结构化的事件信息。现有的篇章级事件抽取模型往往关注纯文本文档，无法有效利用表格文本的位置信息辅助抽取文档表格中包含的事件要素。因此，该文构建了新的含表格文档事件抽取数据集TableEE，用于检测不同模型在此情景下的表现。为提升模型对于表格文本的抽取能力，该文提出了一种绝对位置编码UPEST 来统一表示表格和段落文本的位置信息，增强模型针对含表格文档的语义理解。实验结果表明，该文模型在新构造数据集上事件抽取平均F1 值达到76.91\\%，事件要素抽取平均F1 值在使用UPEST 后提升1.83\\%。},\n}",
        "authors": {
            "boldAuthors": ["朱桐"],
            "correspondingAuthors": ["陈文亮"],
            "equalContributionAuthors": null
        },
        "note": "",
        "resources": {
            "slides": null,
            "video": null,
            "code": "https://github.com/fairyshine/TableEE",
            "demo": null
        }
    },
    {
        "bibtex": "@inproceedings{yu-etal-2023-ji,    title = \"基于句法特征的事件要素抽取方法(Syntax-aware Event Argument Extraction )\",    author = \"Yu, Zijian  and      Zhu, Tong  and      Chen, Wenliang\",    booktitle = \"Proceedings of the 22nd Chinese National Conference on Computational Linguistics\",    month = aug,    year = \"2023\",    address = \"Harbin, China\",    publisher = \"Chinese Information Processing Society of China\",    url = \"https://aclanthology.org/2023.ccl-1.18\",    pages = \"196--207\",    abstract = \"{``}事件要素抽取(Event Argument Extraction, EAE)旨在从非结构化文本中提取事件参与要素。编码器{---}解码器(Encoder-Decoder)框架是处理该任务的一种常见策略,此前的研究大多只向编码器端输入文本的字词信息,导致模型泛化和远程依赖处理能力较弱。为此,本文提出一种融入句法信息的事件要素抽取模型。首先对文本分析得到成分句法解析树,将词性标签和各节点的句法成分标签编码,增强模型的文本表征能力。然后,本文提出了一种基于树结构的注意力机制(Tree-Attention)辅助模型更好地感知结构化语义信息,提高模型处理远距离依赖的能力。实验结果表明,本文所提方法相较于基线系统F1值提升2.02{\\%},证明该方法的有效性。{''}\",    language = \"Chinese\",}",
        "authors": {
            "boldAuthors": ["Tong Zhu"],
            "correspondingAuthors": ["Wenliang Chen"],
            "equalContributionAuthors": null
        },
        "note": "",
        "resources": {
            "slides": null,
            "video": null,
            "code": null,
            "demo": null
        }
    },
    {
        "bibtex": "@inproceedings{ren-etal-2023-ji,    title = \"基于不完全标注的自监督多标签文本分类(Self-Training With Incomplete Labeling For Multi-Label Text Classification)\",    author = \"Ren, Junfei  and      Zhu, Tong  and      Chen, Wenliang\",    booktitle = \"Proceedings of the 22nd Chinese National Conference on Computational Linguistics\",    month = aug,    year = \"2023\",    address = \"Harbin, China\",    publisher = \"Chinese Information Processing Society of China\",    url = \"https://aclanthology.org/2023.ccl-1.2\",    pages = \"17--30\",    abstract = \"{``}多标签文本分类((Multi-Label Text Classification, MLTC)旨在从预定义的候选标签集合中选择一个或多个文本对应的类别,是自然语言处理C)旨在从预定义的候选标签集合中选择一个或多个文本对应的类别,是自然语言处理(Natural Language Processing,NLP)的一项基本任务。前人工作大多基于规范且全面的标注数据集,而这些规范数据集需要严格的质量控制,一般很难获取。在真实的标注过程中,难免会丢失掉一些相关标签,进而导致不完全标注问题。为此本文提出了一种基于局部标注的自监督框架(Partial Self-Training,PST),该框架利用教师模型自动地给大规模无标注数据打伪标签,同时给不完全标注数据补充缺失标签,最后再利用这些数据反向更新教师模型。在合成数据集和真实数据集上的实验表明,本文提出的PST框架兼容现有的各类多标签文本分类模型,并且可以缓解不完全标注数据对模型的影响。{''}\",    language = \"Chinese\",}",
        "authors": {
            "boldAuthors": ["Tong Zhu"],
            "correspondingAuthors": ["Wenliang Chen"],
            "equalContributionAuthors": null
        },
        "note": "",
        "resources": {
            "slides": "./files/任俊飞-基于不完全标注的自监督多标签文本分类.pdf",
            "video": null,
            "code": "https://github.com/15962171082/Incomplete_MLTC",
            "demo": null
        }
    },
    {
        "bibtex": "@article{zhu-et-al-2023-catalog,\n        title={CED: Catalog Extraction from Documents},\n        author={Zhu, Tong and Zhang, Guoliang and Li, Zechang and Yu, Zijian and Ren, Junfei and Wu, Mengsong and Wang, Zhefeng and Huai, Baoxing and Chao, Pingfu and Chen, Wenliang},\n        journal={ICDAR'23 preprint arXiv:2304.14662},\n        year={2023},\n      url = {https://arxiv.org/abs/2304.14662},\n      abstract={Sentence-by-sentence information extraction from long documents is an exhausting and error-prone task. As the indicator of document skeleton, catalogs naturally chunk documents into segments and provide informative cascade semantics, which can help to reduce the search space. Despite their usefulness, catalogs are hard to be extracted without the assist from external knowledge. For documents that adhere to a specific template, regular expressions are practical to extract catalogs. However, handcrafted heuristics are not applicable when processing documents from different sources with diverse formats. To address this problem, we build a large manually annotated corpus, which is the first dataset for the Catalog Extraction from Documents (CED) task. Based on this corpus, we propose a transition-based framework for parsing documents into catalog trees. The experimental results demonstrate that our proposed method outperforms baseline systems and shows a good ability to transfer. We believe the CED task could fill the gap between raw text segments and information extraction tasks on extremely long documents.},\n}",
        "authors": {
            "boldAuthors": ["Tong Zhu"],
            "correspondingAuthors": ["Wenliang Chen"],
            "equalContributionAuthors": null
        },
        "note": "",
        "resources": {
            "slides": "./files/ICDAR23-Poster-6780-CatalogExtraction.pdf",
            "video": null,
            "code": "https://github.com/Spico197/CatalogExtraction",
            "demo": null
        }
    },
    {
        "bibtex": "@article{zhang-et-al-jcip,\n    title={面向无触发词文本的因果关系事件对联合抽取模型},\n    author={张国梁 and 朱桐 and 陈文亮},\n    journal={中文信息学报（暂未见刊）},\n    year={2022},\n    abstract={N/A}\n}",
        "authors": {
            "boldAuthors": ["朱桐"],
            "correspondingAuthors": ["陈文亮"],
            "equalContributionAuthors": null
        },
        "note": "",
        "resources": {
            "slides": null,
            "video": null,
            "code": null,
            "demo": null
        }
    },
    {
        "bibtex": "@inproceedings{ijcai2022p632,\n  title     = {Efficient Document-level Event Extraction via Pseudo-Trigger-aware Pruned Complete Graph},\n  author    = {Zhu, Tong and Qu, Xiaoye and Chen, Wenliang and Wang, Zhefeng and Huai, Baoxing and Yuan, Nicholas and Zhang, Min},\n  booktitle = {Proceedings of the Thirty-First International Joint Conference on\n               Artificial Intelligence, {IJCAI-22}},\n  publisher = {International Joint Conferences on Artificial Intelligence Organization},\n  editor    = {Lud De Raedt},\n  pages     = {4552--4558},\n  year      = {2022},\n  month     = {7},\n  note      = {Main Track},\n  doi       = {10.24963/ijcai.2022/632},\n  url       = {https://doi.org/10.24963/ijcai.2022/632},\n  abstract  = {Most previous studies of document-level event extraction mainly focus on building argument chains in an autoregressive way, which achieves a certain success but is inefficient in both training and inference. In contrast to the previous studies, we propose a fast and lightweight model named as PTPCG. In our model, we design a novel strategy for event argument combination together with a non-autoregressive decoding algorithm via pruned complete graphs, which are constructed under the guidance of the automatically selected pseudo triggers. Compared to the previous systems, our system achieves competitive results with 19.8% of parameters and much lower resource consumption, taking only 3.8% GPU hours for training and up to 8.5 times faster for inference. Besides, our model shows superior compatibility for the datasets with (or without) triggers and the pseudo triggers can be the supplements for annotated triggers to make further improvements. Codes are available at https://github.com/Spico197/DocEE .},\n}\n",
        "authors": {
            "boldAuthors": ["Tong Zhu"],
            "correspondingAuthors": ["Wenliang Chen"],
            "equalContributionAuthors": null
        },
        "note": "",
        "resources": {
            "slides": "./files/84-Tong-AIS2022-PTPCG.pdf",
            "video": "https://slideslive.com/embed/presentation/38984846",
            "code": "https://github.com/Spico197/DocEE",
            "demo": "http://hlt.suda.edu.cn/docee"
        }
    },
    {
        "bibtex": "@article{wang-etal-2021-piee,\n    author = {Wang, Haitao and Zhu, Tong and Wang, Mingtao and Zhang, Guoliang and Chen, Wenliang},\n    title = {A Prior Information Enhanced Extraction Framework for Document-level Financial Event Extraction},\n    journal = {Data Intelligence},\n    volume = {3},\n    number = {3},\n    pages = {460-476},\n    year = {2021},\n    month = {09},\n    issn = {2641-435X},\n    doi = {10.1162/dint_a_00103},\n    url = {https://doi.org/10.1162/dint\\_a\\_00103},\n    eprint = {https://direct.mit.edu/dint/article-pdf/3/3/460/1969115/dint\\_a\\_00103.pdf},\n    abstract = {Document-level financial event extraction (DFEE) is the task of detecting events and extracting the corresponding event arguments in financial documents, which plays an important role in information extraction in the financial domain. This task is challenging as the financial documents are generally long text and event arguments of one event may be scattered in different sentences. To address this issue, we proposed a novel Prior Information Enhanced Extraction framework (PIEE) for DFEE, leveraging prior information from both event types and pre-trained language models. Specifically, PIEE consists of three components: event detection, event argument extraction, and event table filling. In event detection, we identify the event type. Then, the event type is explicitly used for event argument extraction. Meanwhile, the implicit information within language models also provides considerable cues for event arguments localization. Finally, all the event arguments are filled in an event table by a set of predefined heuristic rules. To demonstrate the effectiveness of our proposed framework, we participated in the share task of CCKS2020 Task 4-2: Document-level Event Arguments Extraction. On both Leaderboard A and Leaderboard B, PIEE took the first place and significantly outperformed the other systems.},\n}",
        "authors": {
            "boldAuthors": ["Tong Zhu"],
            "correspondingAuthors": ["Wenliang Chen"],
            "equalContributionAuthors": null
        },
        "note": "",
        "resources": {
            "slides": null,
            "video": null,
            "code": null,
            "demo": "http://hlt.suda.edu.cn/docee"
        }
    },
    {
        "bibtex": "@inproceedings{zhu-etal-2020-nyth, \n    title =  \"Towards Accurate and Consistent Evaluation: A Dataset for Distantly-Supervised Relation Extraction \", \n    author =  \"Zhu, Tong  and \n        Wang, Haitao  and \n        Yu, Junjie  and \n        Zhou, Xiabing  and \n        Chen, Wenliang  and \n        Zhang, Wei  and \n        Zhang, Min \", \n    booktitle =  \"Proceedings of the 28th International Conference on Computational Linguistics \", \n    month = dec, \n    year =  \"2020 \", \n    address =  \"Barcelona, Spain (Online) \", \n    publisher =  \"International Committee on Computational Linguistics \", \n    url =  \"https://aclanthology.org/2020.coling-main.566\", \n    doi =  \"10.18653/v1/2020.coling-main.566 \", \n    pages =  \"6436--6447 \", \n    abstract =  \"In recent years, distantly-supervised relation extraction has achieved a certain success by using deep neural networks. Distant Supervision (DS) can automatically generate large-scale annotated data by aligning entity pairs from Knowledge Bases (KB) to sentences. However, these DS-generated datasets inevitably have wrong labels that result in incorrect evaluation scores during testing, which may mislead the researchers. To solve this problem, we build a new dataset NYTH, where we use the DS-generated data as training data and hire annotators to label test data. Compared with the previous datasets, NYT-H has a much larger test set and then we can perform more accurate and consistent evaluation. Finally, we present the experimental results of several widely used systems on NYT-H. The experimental results show that the ranking lists of the comparison systems on the DS-labelled test data and human-annotated test data are different. This indicates that our human-annotated data is necessary for evaluation of distantly-supervised relation extraction. \", \n}",
        "authors": {
            "boldAuthors": ["Tong Zhu"],
            "correspondingAuthors": ["Xiabing Zhou"],
            "equalContributionAuthors": null
        },
        "note": "",
        "resources": {
            "slides": "./files/Tong-COLING2020-NYT-H.pdf",
            "video": "https://www.bilibili.com/video/BV1AG4y1C7Je/",
            "code": "https://github.com/Spico197/NYT-H",
            "demo": null
        }
    },
    {
        "bibtex": "@inproceedings{yu-etal-2020-rep,\n    title = \"Improving Relation Extraction with Relational Paraphrase Sentences\", \n    author = \"Yu, Junjie  and Zhu, Tong  and Chen, Wenliang  and Zhang, Wei  and Zhang, Min\", \n    booktitle = \"Proceedings of the 28th International Conference on Computational Linguistics\", \n    month = dec, \n    year = \"2020\", \n    address = \"Barcelona, Spain (Online)\", \n    publisher = \"International Committee on Computational Linguistics\", \n    url = \"https://aclanthology.org/2020.coling-main.148\", \n    doi = \"10.18653/v1/2020.coling-main.148\", \n    pages = \"1687--1698\", \n    abstract = \"Supervised models for Relation Extraction (RE) typically require human-annotated training data. Due to the limited size, the human-annotated data is usually incapable of covering diverse relation expressions, which could limit the performance of RE. To increase the coverage of relation expressions, we may enlarge the labeled data by hiring annotators or applying Distant Supervision (DS). However, the human-annotated data is costly and non-scalable while the distantly supervised data contains many noises. In this paper, we propose an alternative approach to improve RE systems via enriching diverse expressions by relational paraphrase sentences. Based on an existing labeled data, we first automatically build a task-specific paraphrase data. Then, we propose a novel model to learn the information of diverse relation expressions. In our model, we try to capture this information on the paraphrases via a joint learning framework. Finally, we conduct experiments on a widely used dataset and the experimental results show that our approach is effective to improve the performance on relation extraction, even compared with a strong baseline.\",\n}",
        "authors": {
            "boldAuthors": ["Tong Zhu"],
            "correspondingAuthors": ["Wenliang Chen"],
            "equalContributionAuthors": []
        },
        "note": "",
        "resources": {
            "slides": null,
            "video": null,
            "code": "https://github.com/jjyunlp/ReP-RE",
            "demo": null
        }
    },
    {
        "bibtex": "@misc{wang-etal-2019-ccks, \n    doi = {10.48550/ARXIV.1908.11337}, \n    url = {https://arxiv.org/abs/1908.11337}, \n    author = {Wang, Haitao and He, Zhengqiu and Zhu, Tong and Shao, Hao and Chen, Wenliang and Zhang, Min},\n    keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences}, \n    title = {CCKS 2019 Shared Task on Inter-Personal Relationship Extraction}, \n    publisher = {arXiv}, \n    year = {2019}, \n    copyright = {arXiv.org perpetual, non-exclusive license}, \n    journal = {arXiv preprint}, \n    abstract={The CCKS2019 shared task was devoted to inter-personal relationship extraction. Given two person entities and at least one sentence containing these two entities, participating teams are asked to predict the relationship between the entities according to a given relation list. This year, 358 teams from various universities and organizations participated in this task. In this paper, we present the task definition, the description of data and the evaluation methodology used during this shared task. We also present a brief overview of the various methods adopted by the participating teams. Finally, we present the evaluation results.},\n}",
        "authors": {
            "boldAuthors": ["Tong Zhu"],
            "correspondingAuthors": ["Wenliang Chen"],
            "equalContributionAuthors": []
        },
        "note": "",
        "resources": {
            "slides": null,
            "video": null,
            "code": null,
            "demo": null
        }
    }
]